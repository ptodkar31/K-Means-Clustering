# -*- coding: utf-8 -*-
"""
Created on Wed Feb 21 23:02:28 2024

@author: Priyanka
"""

"""
#Perform clustering for the crime data and identify the number of clusters            
formed and draw inferences. Refer to crime_data.csv dataset.

Business Problem :-
Q.What is the business objective?
In  present  scenario  criminals  are  becoming  technologically sophisticated in committing crime
and one challenge faced by intelligence  and  law  enforcement  agencies
is  difficulty  in analyzing large volume of data involved in crime 
and terrorist activities therefore agencies need to know technique to catch criminal
and  remain ahead  in  the  eternal race  between  the criminals and the law enforcement.
So appropriate field need to chosen to perform crime analysis and as data mining refers to
extracting  or  mining  knowledge  from  large  amounts  of data, data mining is used 
here on high  volume crime dataset and knowledge gained from data mining approaches is 
useful and  support  police  forces.
Q.Are there any constraints?
Given dataset is smaller,hence contraints on finding inferences


"""


import pandas as pd
import numpy as np
import matplotlib.pylab as plt
from sklearn.cluster import KMeans

crime=pd.read_csv("C:\Data Set\crime_data.csv")
'''

Data Description:
Murder -- Muder rates in different places of United States
Assualt- Assualt rate in different places of United States
UrbanPop - urban population in different places of United States
Rape - Rape rate in different places of United States
'''
#EDA
crime.describe()
# there are average 7.78 murders and 179.76 asaults and 21.23 Rape for an average population 65.54
# max.murders are 17.40 ,assualts 337 and 46 Rape

plt.hist(data = crime, x = 'Murder');
#This is apparently almost a normal distribution.
plt.hist(data = crime, x = 'Assault');
#It is also almost normallly distributed
plt.hist(data = crime, x = 'Rape');
##It is normally distributed with right skewed

# we know that there is scale difference among the columns,which we have to remove
#either by using normalization or standardization
crime=crime.drop(["Unnamed: 0"],axis=1)
def norm_func(i):
    x=(i-i.min())/(i.max()-i.min())
    return x
# Now apply this normalization function to airlines datframe for all the rows and column from 1 until end

df_norm=norm_func(crime.iloc[:,:])
TWSS=[]
k=list(range(2,5))
# The values generated by TWSS are 12 and two get x and y values 12 by 12 ,range has been changed 2:14

for i in k:
    kmeans=KMeans(n_clusters=i)
    kmeans.fit(df_norm)
    TWSS.append(kmeans.inertia_)
TWSS
model1=KMeans(n_clusters=3)
plt.plot(k,TWSS,'ro-');plt.xlabel("No_of_clusters");plt.ylabel("Total_within_SS")
# from the plot it is clear that the TWSS is reducing from k=2 to 3 
#than any other change in values of k,hence k=3 is selected
model=KMeans(n_clusters=3)
model.fit(df_norm)
model.labels_
mb=pd.Series(model.labels_)
crime['clust']=mb
crime.head()
crime=crime.iloc[:,[4,0,1,2,3]]

crime.iloc[:,:].groupby(crime.clust).mean()
#cluster 0 has data entities whose crime is 12.33,assault is 259.31 rape are 29.21

crime.to_csv("kmeans_crime.csv",encoding="utf-8")
import os
os.getcwd()